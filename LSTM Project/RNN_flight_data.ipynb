{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.0"
    },
    "colab": {
      "name": "RNN_flight_data.ipynb",
      "provenance": []
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "VQUa-qy2-dE3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas\n",
        "import math\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import LSTM\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.metrics import mean_squared_error\n",
        "import matplotlib.pyplot as plt\n",
        "from torch.autograd import Variable\n",
        "import torch\n",
        "import numpy as np\n",
        "from torch import nn\n",
        "from torch import optim\n",
        "import torch.nn.functional as F\n",
        "from keras.layers import LSTM"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fxzR5yiT-guR",
        "colab_type": "code",
        "outputId": "e6cbd14d-f144-4bce-d3dc-c9ea4bb60409",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c9PU4Or_-jqg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "DRIVE_DIR = '/content/drive/My Drive/Deep/flight_data (1).csv'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VjDZE5LUHLpg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Encoder(nn.Module):\n",
        "    \"\"\"encoder in DA_RNN.\"\"\"\n",
        "\n",
        "    def __init__(self, T,\n",
        "                 input_size,\n",
        "                 encoder_num_hidden,\n",
        "                 parallel=False):\n",
        "        \"\"\"Initialize an encoder in DA_RNN.\"\"\"\n",
        "        super(Encoder, self).__init__()\n",
        "        self.encoder_num_hidden = encoder_num_hidden\n",
        "        self.input_size = input_size\n",
        "        self.parallel = parallel\n",
        "        self.T = T\n",
        "\n",
        "        # Fig 1. Temporal Attention Mechanism: Encoder is LSTM\n",
        "        self.encoder_lstm = nn.LSTM(\n",
        "            input_size=self.input_size,\n",
        "            hidden_size=self.encoder_num_hidden,\n",
        "            num_layers = 1\n",
        "        )\n",
        "\n",
        "        # Construct Input Attention Mechanism via deterministic attention model\n",
        "        # Eq. 8: W_e[h_{t-1}; s_{t-1}] + U_e * x^k\n",
        "        self.encoder_attn = nn.Linear(\n",
        "            in_features=2 * self.encoder_num_hidden + self.T - 1,\n",
        "            out_features=1\n",
        "        )\n",
        "\n",
        "    def forward(self, X):\n",
        "        \"\"\"forward.\n",
        "\n",
        "        Args:\n",
        "            X: input data\n",
        "\n",
        "        \"\"\"\n",
        "        X_tilde = Variable(X.data.new(\n",
        "            X.size(0), self.T - 1, self.input_size).zero_())\n",
        "        X_encoded = Variable(X.data.new(\n",
        "            X.size(0), self.T - 1, self.encoder_num_hidden).zero_())\n",
        "\n",
        "        # Eq. 8, parameters not in nn.Linear but to be learnt\n",
        "        # v_e = torch.nn.Parameter(data=torch.empty(\n",
        "        #     self.input_size, self.T).uniform_(0, 1), requires_grad=True)\n",
        "        # U_e = torch.nn.Parameter(data=torch.empty(\n",
        "        #     self.T, self.T).uniform_(0, 1), requires_grad=True)\n",
        "\n",
        "        # h_n, s_n: initial states with dimention hidden_size\n",
        "        h_n = self._init_states(X)\n",
        "        s_n = self._init_states(X)\n",
        "\n",
        "        for t in range(self.T - 1):\n",
        "            # batch_size * input_size * (2 * hidden_size + T - 1)\n",
        "            x = torch.cat((h_n.repeat(self.input_size, 1, 1).permute(1, 0, 2),\n",
        "                           s_n.repeat(self.input_size, 1, 1).permute(1, 0, 2),\n",
        "                           X.permute(0, 2, 1)), dim=2)\n",
        "\n",
        "            x = self.encoder_attn(\n",
        "                x.view(-1, self.encoder_num_hidden * 2 + self.T - 1))\n",
        "\n",
        "            # get weights by softmax\n",
        "            alpha = F.softmax(x.view(-1, self.input_size))\n",
        "\n",
        "            # get new input for LSTM\n",
        "            x_tilde = torch.mul(alpha, X[:, t, :])\n",
        "\n",
        "            # Fix the warning about non-contiguous memory\n",
        "            # https://discuss.pytorch.org/t/dataparallel-issue-with-flatten-parameter/8282\n",
        "            self.encoder_lstm.flatten_parameters()\n",
        "\n",
        "            # encoder LSTM\n",
        "            _, final_state = self.encoder_lstm(x_tilde.unsqueeze(0), (h_n, s_n))\n",
        "            h_n = final_state[0]\n",
        "            s_n = final_state[1]\n",
        "\n",
        "            X_tilde[:, t, :] = x_tilde\n",
        "            X_encoded[:, t, :] = h_n\n",
        "\n",
        "        return X_tilde, X_encoded\n",
        "\n",
        "    def _init_states(self, X):\n",
        "        \"\"\"Initialize all 0 hidden states and cell states for encoder.\n",
        "\n",
        "        Args:\n",
        "            X\n",
        "\n",
        "        Returns:\n",
        "            initial_hidden_states\n",
        "        \"\"\"\n",
        "        # https://pytorch.org/docs/master/nn.html?#lstm\n",
        "        return Variable(X.data.new(1, X.size(0), self.encoder_num_hidden).zero_())\n",
        "\n",
        "from keras.layers import LSTM as DARNN\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "class Decoder(nn.Module):\n",
        "    \"\"\"decoder in DA_RNN.\"\"\"\n",
        "\n",
        "    def __init__(self, T, decoder_num_hidden, encoder_num_hidden):\n",
        "        \"\"\"Initialize a decoder in DA_RNN.\"\"\"\n",
        "        super(Decoder, self).__init__()\n",
        "        self.decoder_num_hidden = decoder_num_hidden\n",
        "        self.encoder_num_hidden = encoder_num_hidden\n",
        "        self.T = T\n",
        "\n",
        "        self.attn_layer = nn.Sequential(\n",
        "            nn.Linear(2 * decoder_num_hidden + encoder_num_hidden, encoder_num_hidden),\n",
        "            nn.Tanh(),\n",
        "            nn.Linear(encoder_num_hidden, 1)\n",
        "        )\n",
        "        self.lstm_layer = nn.LSTM(\n",
        "            input_size=1,\n",
        "            hidden_size=decoder_num_hidden\n",
        "        )\n",
        "        self.fc = nn.Linear(encoder_num_hidden + 1, 1)\n",
        "        self.fc_final = nn.Linear(decoder_num_hidden + encoder_num_hidden, 1)\n",
        "\n",
        "        self.fc.weight.data.normal_()\n",
        "\n",
        "    def forward(self, X_encoded, y_prev):\n",
        "        \"\"\"forward.\"\"\"\n",
        "        d_n = self._init_states(X_encoded)\n",
        "        c_n = self._init_states(X_encoded)\n",
        "\n",
        "        for t in range(self.T - 1):\n",
        "\n",
        "            x = torch.cat((d_n.repeat(self.T - 1, 1, 1).permute(1, 0, 2),\n",
        "                           c_n.repeat(self.T - 1, 1, 1).permute(1, 0, 2),\n",
        "                           X_encoded), dim=2)\n",
        "\n",
        "            beta = F.softmax(self.attn_layer(\n",
        "                x.view(-1, 2 * self.decoder_num_hidden + self.encoder_num_hidden)).view(-1, self.T - 1))\n",
        "\n",
        "            # Eqn. 14: compute context vector\n",
        "            # batch_size * encoder_hidden_size\n",
        "            context = torch.bmm(beta.unsqueeze(1), X_encoded)[:, 0, :]\n",
        "            if t < self.T - 1:\n",
        "                # Eqn. 15\n",
        "                # batch_size * 1\n",
        "                y_tilde = self.fc(\n",
        "                    torch.cat((context, y_prev[:, t].unsqueeze(1)), dim=1))\n",
        "\n",
        "                # Eqn. 16: LSTM\n",
        "                self.lstm_layer.flatten_parameters()\n",
        "                _, final_states = self.lstm_layer(\n",
        "                    y_tilde.unsqueeze(0), (d_n, c_n))\n",
        "\n",
        "                d_n = final_states[0]  # 1 * batch_size * decoder_num_hidden\n",
        "                c_n = final_states[1]  # 1 * batch_size * decoder_num_hidden\n",
        "\n",
        "        # Eqn. 22: final output\n",
        "        y_pred = self.fc_final(torch.cat((d_n[0], context), dim=1))\n",
        "\n",
        "        return y_pred\n",
        "\n",
        "    def _init_states(self, X):\n",
        "        \"\"\"Initialize all 0 hidden states and cell states for encoder.\n",
        "\n",
        "        Args:\n",
        "            X\n",
        "        Returns:\n",
        "            initial_hidden_states\n",
        "\n",
        "        \"\"\"\n",
        "        # hidden state and cell state [num_layers*num_directions, batch_size, hidden_size]\n",
        "        # https://pytorch.org/docs/master/nn.html?#lstm\n",
        "        return Variable(X.data.new(1, X.size(0), self.decoder_num_hidden).zero_())\n",
        "\n",
        "\n",
        "class DA_rnn(nn.Module):\n",
        "    \"\"\"da_rnn.\"\"\"\n",
        "\n",
        "    def __init__(self, X, y, T,\n",
        "                 encoder_num_hidden,\n",
        "                 decoder_num_hidden,\n",
        "                 batch_size,\n",
        "                 learning_rate,\n",
        "                 epochs,\n",
        "                 parallel=False):\n",
        "        \"\"\"da_rnn initialization.\"\"\"\n",
        "        super(DA_rnn, self).__init__()\n",
        "        self.encoder_num_hidden = encoder_num_hidden\n",
        "        self.decoder_num_hidden = decoder_num_hidden\n",
        "        self.learning_rate = learning_rate\n",
        "        self.batch_size = batch_size\n",
        "        self.parallel = parallel\n",
        "        self.shuffle = False\n",
        "        self.epochs = epochs\n",
        "        self.T = T\n",
        "        self.X = X\n",
        "        self.y = y\n",
        "\n",
        "        self.device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
        "        print(\"==> Use accelerator: \", self.device)\n",
        "\n",
        "        self.Encoder = Encoder(input_size=X.shape[1],\n",
        "                               encoder_num_hidden=encoder_num_hidden,\n",
        "                               T=T).to(self.device)\n",
        "        self.Decoder = Decoder(encoder_num_hidden=encoder_num_hidden,\n",
        "                               decoder_num_hidden=decoder_num_hidden,\n",
        "                               T=T).to(self.device)\n",
        "\n",
        "        # Loss function\n",
        "        self.criterion = nn.MSELoss()\n",
        "\n",
        "        if self.parallel:\n",
        "            self.encoder = nn.DataParallel(self.encoder)\n",
        "            self.decoder = nn.DataParallel(self.decoder)\n",
        "\n",
        "        self.encoder_optimizer = optim.Adam(params=filter(lambda p: p.requires_grad,\n",
        "                                                          self.Encoder.parameters()),\n",
        "                                            lr=self.learning_rate)\n",
        "        self.decoder_optimizer = optim.Adam(params=filter(lambda p: p.requires_grad,\n",
        "                                                          self.Decoder.parameters()),\n",
        "                                            lr=self.learning_rate)\n",
        "\n",
        "        # Training set\n",
        "        self.train_timesteps = int(self.X.shape[0] * 0.7)\n",
        "        self.y = self.y - np.mean(self.y[:self.train_timesteps])\n",
        "        self.input_size = self.X.shape[1]\n",
        "\n",
        "    def train(self):\n",
        "        \"\"\"training process.\"\"\"\n",
        "        iter_per_epoch = int(np.ceil(self.train_timesteps * 1. / self.batch_size))\n",
        "        self.iter_losses = np.zeros(self.epochs * iter_per_epoch)\n",
        "        self.epoch_losses = np.zeros(self.epochs)\n",
        "\n",
        "        n_iter = 0\n",
        "\n",
        "        for epoch in range(self.epochs):\n",
        "            if self.shuffle:\n",
        "                ref_idx = np.random.permutation(self.train_timesteps - self.T)\n",
        "            else:\n",
        "                ref_idx = np.array(range(self.train_timesteps - self.T))\n",
        "\n",
        "            idx = 0\n",
        "\n",
        "            while (idx < self.train_timesteps):\n",
        "                # get the indices of X_train\n",
        "                indices = ref_idx[idx:(idx + self.batch_size)]\n",
        "                # x = np.zeros((self.T - 1, len(indices), self.input_size))\n",
        "                x = np.zeros((len(indices), self.T - 1, self.input_size))\n",
        "                y_prev = np.zeros((len(indices), self.T - 1))\n",
        "                y_gt = self.y[indices + self.T]\n",
        "\n",
        "                # format x into 3D tensor\n",
        "                for bs in range(len(indices)):\n",
        "                    x[bs, :, :] = self.X[indices[bs]:(indices[bs] + self.T - 1), :]\n",
        "                    y_prev[bs, :] = self.y[indices[bs]: (indices[bs] + self.T - 1)]\n",
        "\n",
        "                loss = self.train_forward(x, y_prev, y_gt)\n",
        "                self.iter_losses[int(epoch * iter_per_epoch + idx / self.batch_size)] = loss\n",
        "\n",
        "                idx += self.batch_size\n",
        "                n_iter += 1\n",
        "\n",
        "                if n_iter % 10000 == 0 and n_iter != 0:\n",
        "                    for param_group in self.encoder_optimizer.param_groups:\n",
        "                        param_group['lr'] = param_group['lr'] * 0.9\n",
        "                    for param_group in self.decoder_optimizer.param_groups:\n",
        "                        param_group['lr'] = param_group['lr'] * 0.9\n",
        "\n",
        "                self.epoch_losses[epoch] = np.mean(self.iter_losses[range(\n",
        "                    epoch * iter_per_epoch, (epoch + 1) * iter_per_epoch)])\n",
        "\n",
        "            if epoch % 10 == 0:\n",
        "                print(\"Epochs: \", epoch, \" Iterations: \", n_iter,\n",
        "                      \" Loss: \", self.epoch_losses[epoch])\n",
        "\n",
        "            if epoch % 10 == 0:\n",
        "                y_train_pred = self.test(on_train=True)\n",
        "                y_test_pred = self.test(on_train=False)\n",
        "                y_pred = np.concatenate((y_train_pred, y_test_pred))\n",
        "                plt.ioff()\n",
        "                plt.figure()\n",
        "                plt.plot(range(1, 1 + len(self.y)), self.y, label=\"True\")\n",
        "                plt.plot(range(self.T, len(y_train_pred) + self.T),\n",
        "                         y_train_pred, label='Predicted - Train')\n",
        "                plt.plot(range(self.T + len(y_train_pred), len(self.y) + 1),\n",
        "                         y_test_pred, label='Predicted - Test')\n",
        "                plt.legend(loc='upper left')\n",
        "                plt.show()\n",
        "\n",
        "            # # Save files in last iterations\n",
        "            # if epoch == self.epochs - 1:\n",
        "            #     np.savetxt('../loss.txt', np.array(self.epoch_losses), delimiter=',')\n",
        "            #     np.savetxt('../y_pred.txt',\n",
        "            #                np.array(self.y_pred), delimiter=',')\n",
        "            #     np.savetxt('../y_true.txt',\n",
        "            #                np.array(self.y_true), delimiter=',')\n",
        "\n",
        "    def train_forward(self, X, y_prev, y_gt):\n",
        "        \"\"\"\n",
        "        Forward pass.\n",
        "\n",
        "        Args:\n",
        "            X:\n",
        "            y_prev:\n",
        "            y_gt: Ground truth label\n",
        "\n",
        "        \"\"\"\n",
        "        # zero gradients\n",
        "        self.encoder_optimizer.zero_grad()\n",
        "        self.decoder_optimizer.zero_grad()\n",
        "\n",
        "        input_weighted, input_encoded = self.Encoder(\n",
        "            Variable(torch.from_numpy(X).type(torch.FloatTensor).to(self.device)))\n",
        "        y_pred = self.Decoder(input_encoded, Variable(\n",
        "            torch.from_numpy(y_prev).type(torch.FloatTensor).to(self.device)))\n",
        "\n",
        "        y_true = Variable(torch.from_numpy(\n",
        "            y_gt).type(torch.FloatTensor).to(self.device))\n",
        "\n",
        "        y_true = y_true.view(-1, 1)\n",
        "        loss = self.criterion(y_pred, y_true)\n",
        "        loss.backward()\n",
        "\n",
        "        self.encoder_optimizer.step()\n",
        "        self.decoder_optimizer.step()\n",
        "\n",
        "        return loss.item()\n",
        "\n",
        "\n",
        "    def test(self, on_train=False):\n",
        "        \"\"\"test.\"\"\"\n",
        "\n",
        "        if on_train:\n",
        "            y_pred = np.zeros(self.train_timesteps - self.T + 1)\n",
        "        else:\n",
        "            y_pred = np.zeros(self.X.shape[0] - self.train_timesteps)\n",
        "\n",
        "        i = 0\n",
        "        while i < len(y_pred):\n",
        "            batch_idx = np.array(range(len(y_pred)))[i: (i + self.batch_size)]\n",
        "            X = np.zeros((len(batch_idx), self.T - 1, self.X.shape[1]))\n",
        "            y_history = np.zeros((len(batch_idx), self.T - 1))\n",
        "\n",
        "            for j in range(len(batch_idx)):\n",
        "                if on_train:\n",
        "                    X[j, :, :] = self.X[range(\n",
        "                        batch_idx[j], batch_idx[j] + self.T - 1), :]\n",
        "                    y_history[j, :] = self.y[range(\n",
        "                        batch_idx[j], batch_idx[j] + self.T - 1)]\n",
        "                else:\n",
        "                    X[j, :, :] = self.X[range(\n",
        "                        batch_idx[j] + self.train_timesteps - self.T, batch_idx[j] + self.train_timesteps - 1), :]\n",
        "                    y_history[j, :] = self.y[range(\n",
        "                        batch_idx[j] + self.train_timesteps - self.T, batch_idx[j] + self.train_timesteps - 1)]\n",
        "\n",
        "            y_history = Variable(torch.from_numpy(\n",
        "                y_history).type(torch.FloatTensor).to(self.device))\n",
        "            _, input_encoded = self.Encoder(\n",
        "                Variable(torch.from_numpy(X).type(torch.FloatTensor).to(self.device)))\n",
        "            y_pred[i:(i + self.batch_size)] = self.Decoder(input_encoded,\n",
        "                                                           y_history).cpu().data.numpy()[:, 0]\n",
        "            i += self.batch_size\n",
        "\n",
        "        return y_pred\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "\n",
        "def read_data(input_path, debug=True):\n",
        "    \"\"\"Read nasdaq stocks data.\n",
        "\n",
        "    Args:\n",
        "        input_path (str): directory to nasdaq dataset.\n",
        "\n",
        "    Returns:\n",
        "        X (np.ndarray): features.\n",
        "        y (np.ndarray): ground truth.\n",
        "\n",
        "    \"\"\"\n",
        "    df = pd.read_csv(input_path, nrows=250 if debug else None)\n",
        "    # X = df.iloc[:, 0:-1].values\n",
        "    X = df.loc[:, [x for x in df.columns.tolist() if x != 'NDX']].as_matrix()\n",
        "    # y = df.iloc[:, -1].values\n",
        "    y = np.array(df.NDX)\n",
        "\n",
        "    return X, y"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z23WKHSj-dE7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "numpy.random.seed(7)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sxmuxwsS-dE9",
        "colab_type": "code",
        "outputId": "7701ccfe-0ba6-4bba-f698-dc26f0ce641c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import locale\n",
        "import numpy as np\n",
        "locale.setlocale(locale.LC_ALL, 'en_US.UTF8')"
      ],
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'en_US.UTF8'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VWTzZP7_-dFB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dataframe = pandas.read_csv(DRIVE_DIR, usecols=[1], engine='python')\n",
        "dataset = dataframe.values\n",
        "#dataset = dataset.astype('float32')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qdpK1A5GAouw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X= []\n",
        "for x in dataset:\n",
        "  X.append([int(x[0].replace(',',''))])\n",
        "dataset =np.array(X)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "paoHMa8n-dFE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "scaler = MinMaxScaler(feature_range=(0, 1))\n",
        "dataset = scaler.fit_transform(dataset)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qEfN9doh-dFG",
        "colab_type": "code",
        "outputId": "d8d63490-db36-41a6-8dfd-c4aa6df417b5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "train_size = int(len(dataset) * 0.67)\n",
        "test_size = len(dataset) - train_size\n",
        "train, test = dataset[0:train_size,:], dataset[train_size:len(dataset),:]\n",
        "print(len(train), len(test))"
      ],
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "136 67\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-tE__HXR-dFI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# convert an array of values into a dataset matrix\n",
        "def create_dataset(dataset, look_back=1):\n",
        "\tdataX, dataY = [], []\n",
        "\tfor i in range(len(dataset)-look_back-1):\n",
        "\t\ta = dataset[i:(i+look_back), 0]\n",
        "\t\tdataX.append(a)\n",
        "\t\tdataY.append(dataset[i + look_back, 0])\n",
        "\treturn numpy.array(dataX), numpy.array(dataY)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zq9A3WpX-dFK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# reshape into X=t and Y=t+1\n",
        "look_back = 1\n",
        "trainX, trainY = create_dataset(train, look_back)\n",
        "testX, testY = create_dataset(test, look_back)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BxLaMM9w-dFM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# reshape input to be [samples, time steps, features]\n",
        "trainX = numpy.reshape(trainX, (trainX.shape[0], 1, trainX.shape[1]))\n",
        "testX = numpy.reshape(testX, (testX.shape[0], 1, testX.shape[1]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r0SRkcr_-dFO",
        "colab_type": "code",
        "outputId": "0469e98a-b2b9-47d5-e7e0-7b02e191d08c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# create and fit the LSTM network\n",
        "model = Sequential()\n",
        "model.add(DARNN(4, input_shape=(1, look_back)))\n",
        "model.add(Dense(1))\n",
        "model.compile(loss='mean_squared_error', optimizer='rmsprop')\n",
        "model.fit(trainX, trainY, epochs=500, batch_size=1, verbose=2)"
      ],
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/500\n",
            " - 1s - loss: 0.0642\n",
            "Epoch 2/500\n",
            " - 0s - loss: 0.0186\n",
            "Epoch 3/500\n",
            " - 0s - loss: 0.0138\n",
            "Epoch 4/500\n",
            " - 0s - loss: 0.0136\n",
            "Epoch 5/500\n",
            " - 0s - loss: 0.0134\n",
            "Epoch 6/500\n",
            " - 0s - loss: 0.0133\n",
            "Epoch 7/500\n",
            " - 0s - loss: 0.0131\n",
            "Epoch 8/500\n",
            " - 0s - loss: 0.0130\n",
            "Epoch 9/500\n",
            " - 0s - loss: 0.0128\n",
            "Epoch 10/500\n",
            " - 0s - loss: 0.0127\n",
            "Epoch 11/500\n",
            " - 0s - loss: 0.0126\n",
            "Epoch 12/500\n",
            " - 0s - loss: 0.0125\n",
            "Epoch 13/500\n",
            " - 0s - loss: 0.0124\n",
            "Epoch 14/500\n",
            " - 0s - loss: 0.0123\n",
            "Epoch 15/500\n",
            " - 0s - loss: 0.0122\n",
            "Epoch 16/500\n",
            " - 0s - loss: 0.0122\n",
            "Epoch 17/500\n",
            " - 0s - loss: 0.0121\n",
            "Epoch 18/500\n",
            " - 0s - loss: 0.0121\n",
            "Epoch 19/500\n",
            " - 0s - loss: 0.0120\n",
            "Epoch 20/500\n",
            " - 0s - loss: 0.0119\n",
            "Epoch 21/500\n",
            " - 0s - loss: 0.0119\n",
            "Epoch 22/500\n",
            " - 0s - loss: 0.0119\n",
            "Epoch 23/500\n",
            " - 0s - loss: 0.0118\n",
            "Epoch 24/500\n",
            " - 0s - loss: 0.0115\n",
            "Epoch 25/500\n",
            " - 0s - loss: 0.0118\n",
            "Epoch 26/500\n",
            " - 0s - loss: 0.0117\n",
            "Epoch 27/500\n",
            " - 0s - loss: 0.0117\n",
            "Epoch 28/500\n",
            " - 0s - loss: 0.0116\n",
            "Epoch 29/500\n",
            " - 0s - loss: 0.0117\n",
            "Epoch 30/500\n",
            " - 0s - loss: 0.0116\n",
            "Epoch 31/500\n",
            " - 0s - loss: 0.0116\n",
            "Epoch 32/500\n",
            " - 0s - loss: 0.0116\n",
            "Epoch 33/500\n",
            " - 0s - loss: 0.0116\n",
            "Epoch 34/500\n",
            " - 0s - loss: 0.0116\n",
            "Epoch 35/500\n",
            " - 0s - loss: 0.0115\n",
            "Epoch 36/500\n",
            " - 0s - loss: 0.0116\n",
            "Epoch 37/500\n",
            " - 0s - loss: 0.0116\n",
            "Epoch 38/500\n",
            " - 0s - loss: 0.0116\n",
            "Epoch 39/500\n",
            " - 0s - loss: 0.0115\n",
            "Epoch 40/500\n",
            " - 0s - loss: 0.0116\n",
            "Epoch 41/500\n",
            " - 0s - loss: 0.0116\n",
            "Epoch 42/500\n",
            " - 0s - loss: 0.0116\n",
            "Epoch 43/500\n",
            " - 0s - loss: 0.0115\n",
            "Epoch 44/500\n",
            " - 0s - loss: 0.0116\n",
            "Epoch 45/500\n",
            " - 0s - loss: 0.0115\n",
            "Epoch 46/500\n",
            " - 0s - loss: 0.0115\n",
            "Epoch 47/500\n",
            " - 0s - loss: 0.0114\n",
            "Epoch 48/500\n",
            " - 0s - loss: 0.0115\n",
            "Epoch 49/500\n",
            " - 0s - loss: 0.0115\n",
            "Epoch 50/500\n",
            " - 0s - loss: 0.0115\n",
            "Epoch 51/500\n",
            " - 0s - loss: 0.0116\n",
            "Epoch 52/500\n",
            " - 0s - loss: 0.0116\n",
            "Epoch 53/500\n",
            " - 0s - loss: 0.0113\n",
            "Epoch 54/500\n",
            " - 0s - loss: 0.0115\n",
            "Epoch 55/500\n",
            " - 0s - loss: 0.0116\n",
            "Epoch 56/500\n",
            " - 0s - loss: 0.0115\n",
            "Epoch 57/500\n",
            " - 0s - loss: 0.0115\n",
            "Epoch 58/500\n",
            " - 0s - loss: 0.0114\n",
            "Epoch 59/500\n",
            " - 0s - loss: 0.0115\n",
            "Epoch 60/500\n",
            " - 0s - loss: 0.0116\n",
            "Epoch 61/500\n",
            " - 0s - loss: 0.0115\n",
            "Epoch 62/500\n",
            " - 0s - loss: 0.0115\n",
            "Epoch 63/500\n",
            " - 0s - loss: 0.0115\n",
            "Epoch 64/500\n",
            " - 0s - loss: 0.0115\n",
            "Epoch 65/500\n",
            " - 0s - loss: 0.0116\n",
            "Epoch 66/500\n",
            " - 0s - loss: 0.0115\n",
            "Epoch 67/500\n",
            " - 0s - loss: 0.0115\n",
            "Epoch 68/500\n",
            " - 0s - loss: 0.0113\n",
            "Epoch 69/500\n",
            " - 0s - loss: 0.0116\n",
            "Epoch 70/500\n",
            " - 0s - loss: 0.0113\n",
            "Epoch 71/500\n",
            " - 0s - loss: 0.0116\n",
            "Epoch 72/500\n",
            " - 0s - loss: 0.0116\n",
            "Epoch 73/500\n",
            " - 0s - loss: 0.0116\n",
            "Epoch 74/500\n",
            " - 0s - loss: 0.0115\n",
            "Epoch 75/500\n",
            " - 0s - loss: 0.0116\n",
            "Epoch 76/500\n",
            " - 0s - loss: 0.0115\n",
            "Epoch 77/500\n",
            " - 0s - loss: 0.0116\n",
            "Epoch 78/500\n",
            " - 0s - loss: 0.0116\n",
            "Epoch 79/500\n",
            " - 0s - loss: 0.0115\n",
            "Epoch 80/500\n",
            " - 0s - loss: 0.0116\n",
            "Epoch 81/500\n",
            " - 0s - loss: 0.0115\n",
            "Epoch 82/500\n",
            " - 0s - loss: 0.0115\n",
            "Epoch 83/500\n",
            " - 0s - loss: 0.0116\n",
            "Epoch 84/500\n",
            " - 0s - loss: 0.0115\n",
            "Epoch 85/500\n",
            " - 0s - loss: 0.0115\n",
            "Epoch 86/500\n",
            " - 0s - loss: 0.0115\n",
            "Epoch 87/500\n",
            " - 0s - loss: 0.0116\n",
            "Epoch 88/500\n",
            " - 0s - loss: 0.0114\n",
            "Epoch 89/500\n",
            " - 0s - loss: 0.0116\n",
            "Epoch 90/500\n",
            " - 0s - loss: 0.0115\n",
            "Epoch 91/500\n",
            " - 0s - loss: 0.0114\n",
            "Epoch 92/500\n",
            " - 0s - loss: 0.0116\n",
            "Epoch 93/500\n",
            " - 0s - loss: 0.0114\n",
            "Epoch 94/500\n",
            " - 0s - loss: 0.0116\n",
            "Epoch 95/500\n",
            " - 0s - loss: 0.0116\n",
            "Epoch 96/500\n",
            " - 0s - loss: 0.0115\n",
            "Epoch 97/500\n",
            " - 0s - loss: 0.0115\n",
            "Epoch 98/500\n",
            " - 0s - loss: 0.0116\n",
            "Epoch 99/500\n",
            " - 0s - loss: 0.0115\n",
            "Epoch 100/500\n",
            " - 0s - loss: 0.0116\n",
            "Epoch 101/500\n",
            " - 0s - loss: 0.0115\n",
            "Epoch 102/500\n",
            " - 0s - loss: 0.0116\n",
            "Epoch 103/500\n",
            " - 0s - loss: 0.0114\n",
            "Epoch 104/500\n",
            " - 0s - loss: 0.0116\n",
            "Epoch 105/500\n",
            " - 0s - loss: 0.0116\n",
            "Epoch 106/500\n",
            " - 0s - loss: 0.0115\n",
            "Epoch 107/500\n",
            " - 0s - loss: 0.0115\n",
            "Epoch 108/500\n",
            " - 0s - loss: 0.0115\n",
            "Epoch 109/500\n",
            " - 0s - loss: 0.0116\n",
            "Epoch 110/500\n",
            " - 0s - loss: 0.0115\n",
            "Epoch 111/500\n",
            " - 0s - loss: 0.0115\n",
            "Epoch 112/500\n",
            " - 0s - loss: 0.0116\n",
            "Epoch 113/500\n",
            " - 0s - loss: 0.0116\n",
            "Epoch 114/500\n",
            " - 0s - loss: 0.0115\n",
            "Epoch 115/500\n",
            " - 0s - loss: 0.0115\n",
            "Epoch 116/500\n",
            " - 0s - loss: 0.0115\n",
            "Epoch 117/500\n",
            " - 0s - loss: 0.0115\n",
            "Epoch 118/500\n",
            " - 0s - loss: 0.0115\n",
            "Epoch 119/500\n",
            " - 0s - loss: 0.0115\n",
            "Epoch 120/500\n",
            " - 0s - loss: 0.0114\n",
            "Epoch 121/500\n",
            " - 0s - loss: 0.0116\n",
            "Epoch 122/500\n",
            " - 0s - loss: 0.0116\n",
            "Epoch 123/500\n",
            " - 0s - loss: 0.0115\n",
            "Epoch 124/500\n",
            " - 0s - loss: 0.0115\n",
            "Epoch 125/500\n",
            " - 0s - loss: 0.0115\n",
            "Epoch 126/500\n",
            " - 0s - loss: 0.0116\n",
            "Epoch 127/500\n",
            " - 0s - loss: 0.0116\n",
            "Epoch 128/500\n",
            " - 0s - loss: 0.0114\n",
            "Epoch 129/500\n",
            " - 0s - loss: 0.0115\n",
            "Epoch 130/500\n",
            " - 0s - loss: 0.0115\n",
            "Epoch 131/500\n",
            " - 0s - loss: 0.0115\n",
            "Epoch 132/500\n",
            " - 0s - loss: 0.0115\n",
            "Epoch 133/500\n",
            " - 0s - loss: 0.0116\n",
            "Epoch 134/500\n",
            " - 0s - loss: 0.0116\n",
            "Epoch 135/500\n",
            " - 0s - loss: 0.0116\n",
            "Epoch 136/500\n",
            " - 0s - loss: 0.0116\n",
            "Epoch 137/500\n",
            " - 0s - loss: 0.0115\n",
            "Epoch 138/500\n",
            " - 0s - loss: 0.0116\n",
            "Epoch 139/500\n",
            " - 0s - loss: 0.0116\n",
            "Epoch 140/500\n",
            " - 0s - loss: 0.0115\n",
            "Epoch 141/500\n",
            " - 0s - loss: 0.0114\n",
            "Epoch 142/500\n",
            " - 0s - loss: 0.0117\n",
            "Epoch 143/500\n",
            " - 0s - loss: 0.0114\n",
            "Epoch 144/500\n",
            " - 0s - loss: 0.0116\n",
            "Epoch 145/500\n",
            " - 0s - loss: 0.0113\n",
            "Epoch 146/500\n",
            " - 0s - loss: 0.0113\n",
            "Epoch 147/500\n",
            " - 0s - loss: 0.0115\n",
            "Epoch 148/500\n",
            " - 0s - loss: 0.0116\n",
            "Epoch 149/500\n",
            " - 0s - loss: 0.0116\n",
            "Epoch 150/500\n",
            " - 0s - loss: 0.0114\n",
            "Epoch 151/500\n",
            " - 0s - loss: 0.0116\n",
            "Epoch 152/500\n",
            " - 0s - loss: 0.0115\n",
            "Epoch 153/500\n",
            " - 0s - loss: 0.0115\n",
            "Epoch 154/500\n",
            " - 0s - loss: 0.0116\n",
            "Epoch 155/500\n",
            " - 0s - loss: 0.0116\n",
            "Epoch 156/500\n",
            " - 0s - loss: 0.0116\n",
            "Epoch 157/500\n",
            " - 0s - loss: 0.0116\n",
            "Epoch 158/500\n",
            " - 0s - loss: 0.0115\n",
            "Epoch 159/500\n",
            " - 0s - loss: 0.0115\n",
            "Epoch 160/500\n",
            " - 0s - loss: 0.0116\n",
            "Epoch 161/500\n",
            " - 0s - loss: 0.0115\n",
            "Epoch 162/500\n",
            " - 0s - loss: 0.0116\n",
            "Epoch 163/500\n",
            " - 0s - loss: 0.0115\n",
            "Epoch 164/500\n",
            " - 0s - loss: 0.0115\n",
            "Epoch 165/500\n",
            " - 0s - loss: 0.0115\n",
            "Epoch 166/500\n",
            " - 0s - loss: 0.0116\n",
            "Epoch 167/500\n",
            " - 0s - loss: 0.0115\n",
            "Epoch 168/500\n",
            " - 0s - loss: 0.0116\n",
            "Epoch 169/500\n",
            " - 0s - loss: 0.0116\n",
            "Epoch 170/500\n",
            " - 0s - loss: 0.0115\n",
            "Epoch 171/500\n",
            " - 0s - loss: 0.0115\n",
            "Epoch 172/500\n",
            " - 0s - loss: 0.0114\n",
            "Epoch 173/500\n",
            " - 0s - loss: 0.0116\n",
            "Epoch 174/500\n",
            " - 0s - loss: 0.0116\n",
            "Epoch 175/500\n",
            " - 0s - loss: 0.0115\n",
            "Epoch 176/500\n",
            " - 0s - loss: 0.0116\n",
            "Epoch 177/500\n",
            " - 0s - loss: 0.0115\n",
            "Epoch 178/500\n",
            " - 0s - loss: 0.0116\n",
            "Epoch 179/500\n",
            " - 0s - loss: 0.0115\n",
            "Epoch 180/500\n",
            " - 0s - loss: 0.0116\n",
            "Epoch 181/500\n",
            " - 0s - loss: 0.0116\n",
            "Epoch 182/500\n",
            " - 0s - loss: 0.0115\n",
            "Epoch 183/500\n",
            " - 0s - loss: 0.0114\n",
            "Epoch 184/500\n",
            " - 0s - loss: 0.0115\n",
            "Epoch 185/500\n",
            " - 0s - loss: 0.0116\n",
            "Epoch 186/500\n",
            " - 0s - loss: 0.0114\n",
            "Epoch 187/500\n",
            " - 0s - loss: 0.0116\n",
            "Epoch 188/500\n",
            " - 0s - loss: 0.0115\n",
            "Epoch 189/500\n",
            " - 0s - loss: 0.0115\n",
            "Epoch 190/500\n",
            " - 0s - loss: 0.0115\n",
            "Epoch 191/500\n",
            " - 0s - loss: 0.0115\n",
            "Epoch 192/500\n",
            " - 0s - loss: 0.0115\n",
            "Epoch 193/500\n",
            " - 0s - loss: 0.0116\n",
            "Epoch 194/500\n",
            " - 0s - loss: 0.0116\n",
            "Epoch 195/500\n",
            " - 0s - loss: 0.0115\n",
            "Epoch 196/500\n",
            " - 0s - loss: 0.0115\n",
            "Epoch 197/500\n",
            " - 0s - loss: 0.0115\n",
            "Epoch 198/500\n",
            " - 0s - loss: 0.0115\n",
            "Epoch 199/500\n",
            " - 0s - loss: 0.0115\n",
            "Epoch 200/500\n",
            " - 0s - loss: 0.0115\n",
            "Epoch 201/500\n",
            " - 0s - loss: 0.0115\n",
            "Epoch 202/500\n",
            " - 0s - loss: 0.0114\n",
            "Epoch 203/500\n",
            " - 0s - loss: 0.0116\n",
            "Epoch 204/500\n",
            " - 0s - loss: 0.0115\n",
            "Epoch 205/500\n",
            " - 0s - loss: 0.0115\n",
            "Epoch 206/500\n",
            " - 0s - loss: 0.0115\n",
            "Epoch 207/500\n",
            " - 0s - loss: 0.0116\n",
            "Epoch 208/500\n",
            " - 0s - loss: 0.0114\n",
            "Epoch 209/500\n",
            " - 0s - loss: 0.0115\n",
            "Epoch 210/500\n",
            " - 0s - loss: 0.0116\n",
            "Epoch 211/500\n",
            " - 0s - loss: 0.0115\n",
            "Epoch 212/500\n",
            " - 0s - loss: 0.0115\n",
            "Epoch 213/500\n",
            " - 0s - loss: 0.0115\n",
            "Epoch 214/500\n",
            " - 0s - loss: 0.0115\n",
            "Epoch 215/500\n",
            " - 0s - loss: 0.0115\n",
            "Epoch 216/500\n",
            " - 0s - loss: 0.0115\n",
            "Epoch 217/500\n",
            " - 0s - loss: 0.0116\n",
            "Epoch 218/500\n",
            " - 0s - loss: 0.0115\n",
            "Epoch 219/500\n",
            " - 0s - loss: 0.0115\n",
            "Epoch 220/500\n",
            " - 0s - loss: 0.0115\n",
            "Epoch 221/500\n",
            " - 0s - loss: 0.0114\n",
            "Epoch 222/500\n",
            " - 0s - loss: 0.0116\n",
            "Epoch 223/500\n",
            " - 0s - loss: 0.0115\n",
            "Epoch 224/500\n",
            " - 0s - loss: 0.0114\n",
            "Epoch 225/500\n",
            " - 0s - loss: 0.0116\n",
            "Epoch 226/500\n",
            " - 0s - loss: 0.0115\n",
            "Epoch 227/500\n",
            " - 0s - loss: 0.0115\n",
            "Epoch 228/500\n",
            " - 0s - loss: 0.0114\n",
            "Epoch 229/500\n",
            " - 0s - loss: 0.0115\n",
            "Epoch 230/500\n",
            " - 0s - loss: 0.0115\n",
            "Epoch 231/500\n",
            " - 0s - loss: 0.0115\n",
            "Epoch 232/500\n",
            " - 0s - loss: 0.0115\n",
            "Epoch 233/500\n",
            " - 0s - loss: 0.0116\n",
            "Epoch 234/500\n",
            " - 0s - loss: 0.0115\n",
            "Epoch 235/500\n",
            " - 0s - loss: 0.0115\n",
            "Epoch 236/500\n",
            " - 0s - loss: 0.0115\n",
            "Epoch 237/500\n",
            " - 0s - loss: 0.0115\n",
            "Epoch 238/500\n",
            " - 0s - loss: 0.0115\n",
            "Epoch 239/500\n",
            " - 0s - loss: 0.0115\n",
            "Epoch 240/500\n",
            " - 0s - loss: 0.0116\n",
            "Epoch 241/500\n",
            " - 0s - loss: 0.0115\n",
            "Epoch 242/500\n",
            " - 0s - loss: 0.0115\n",
            "Epoch 243/500\n",
            " - 0s - loss: 0.0115\n",
            "Epoch 244/500\n",
            " - 0s - loss: 0.0115\n",
            "Epoch 245/500\n",
            " - 0s - loss: 0.0116\n",
            "Epoch 246/500\n",
            " - 0s - loss: 0.0115\n",
            "Epoch 247/500\n",
            " - 0s - loss: 0.0115\n",
            "Epoch 248/500\n",
            " - 0s - loss: 0.0115\n",
            "Epoch 249/500\n",
            " - 0s - loss: 0.0115\n",
            "Epoch 250/500\n",
            " - 0s - loss: 0.0115\n",
            "Epoch 251/500\n",
            " - 0s - loss: 0.0114\n",
            "Epoch 252/500\n",
            " - 0s - loss: 0.0115\n",
            "Epoch 253/500\n",
            " - 0s - loss: 0.0113\n",
            "Epoch 254/500\n",
            " - 0s - loss: 0.0115\n",
            "Epoch 255/500\n",
            " - 0s - loss: 0.0115\n",
            "Epoch 256/500\n",
            " - 0s - loss: 0.0115\n",
            "Epoch 257/500\n",
            " - 0s - loss: 0.0115\n",
            "Epoch 258/500\n",
            " - 0s - loss: 0.0115\n",
            "Epoch 259/500\n",
            " - 0s - loss: 0.0115\n",
            "Epoch 260/500\n",
            " - 0s - loss: 0.0115\n",
            "Epoch 261/500\n",
            " - 0s - loss: 0.0115\n",
            "Epoch 262/500\n",
            " - 0s - loss: 0.0114\n",
            "Epoch 263/500\n",
            " - 0s - loss: 0.0115\n",
            "Epoch 264/500\n",
            " - 0s - loss: 0.0116\n",
            "Epoch 265/500\n",
            " - 0s - loss: 0.0115\n",
            "Epoch 266/500\n",
            " - 0s - loss: 0.0115\n",
            "Epoch 267/500\n",
            " - 0s - loss: 0.0115\n",
            "Epoch 268/500\n",
            " - 0s - loss: 0.0115\n",
            "Epoch 269/500\n",
            " - 0s - loss: 0.0115\n",
            "Epoch 270/500\n",
            " - 0s - loss: 0.0115\n",
            "Epoch 271/500\n",
            " - 0s - loss: 0.0116\n",
            "Epoch 272/500\n",
            " - 0s - loss: 0.0115\n",
            "Epoch 273/500\n",
            " - 0s - loss: 0.0115\n",
            "Epoch 274/500\n",
            " - 0s - loss: 0.0115\n",
            "Epoch 275/500\n",
            " - 0s - loss: 0.0115\n",
            "Epoch 276/500\n",
            " - 0s - loss: 0.0116\n",
            "Epoch 277/500\n",
            " - 0s - loss: 0.0115\n",
            "Epoch 278/500\n",
            " - 0s - loss: 0.0115\n",
            "Epoch 279/500\n",
            " - 0s - loss: 0.0113\n",
            "Epoch 280/500\n",
            " - 0s - loss: 0.0115\n",
            "Epoch 281/500\n",
            " - 0s - loss: 0.0116\n",
            "Epoch 282/500\n",
            " - 0s - loss: 0.0113\n",
            "Epoch 283/500\n",
            " - 0s - loss: 0.0116\n",
            "Epoch 284/500\n",
            " - 0s - loss: 0.0115\n",
            "Epoch 285/500\n",
            " - 0s - loss: 0.0114\n",
            "Epoch 286/500\n",
            " - 0s - loss: 0.0116\n",
            "Epoch 287/500\n",
            " - 0s - loss: 0.0116\n",
            "Epoch 288/500\n",
            " - 0s - loss: 0.0115\n",
            "Epoch 289/500\n",
            " - 0s - loss: 0.0115\n",
            "Epoch 290/500\n",
            " - 0s - loss: 0.0115\n",
            "Epoch 291/500\n",
            " - 0s - loss: 0.0115\n",
            "Epoch 292/500\n",
            " - 0s - loss: 0.0116\n",
            "Epoch 293/500\n",
            " - 0s - loss: 0.0115\n",
            "Epoch 294/500\n",
            " - 0s - loss: 0.0114\n",
            "Epoch 295/500\n",
            " - 0s - loss: 0.0115\n",
            "Epoch 296/500\n",
            " - 0s - loss: 0.0115\n",
            "Epoch 297/500\n",
            " - 0s - loss: 0.0115\n",
            "Epoch 298/500\n",
            " - 0s - loss: 0.0115\n",
            "Epoch 299/500\n",
            " - 0s - loss: 0.0115\n",
            "Epoch 300/500\n",
            " - 0s - loss: 0.0115\n",
            "Epoch 301/500\n",
            " - 0s - loss: 0.0115\n",
            "Epoch 302/500\n",
            " - 0s - loss: 0.0115\n",
            "Epoch 303/500\n",
            " - 0s - loss: 0.0115\n",
            "Epoch 304/500\n",
            " - 0s - loss: 0.0115\n",
            "Epoch 305/500\n",
            " - 0s - loss: 0.0115\n",
            "Epoch 306/500\n",
            " - 0s - loss: 0.0115\n",
            "Epoch 307/500\n",
            " - 0s - loss: 0.0115\n",
            "Epoch 308/500\n",
            " - 0s - loss: 0.0115\n",
            "Epoch 309/500\n",
            " - 0s - loss: 0.0115\n",
            "Epoch 310/500\n",
            " - 0s - loss: 0.0116\n",
            "Epoch 311/500\n",
            " - 0s - loss: 0.0116\n",
            "Epoch 312/500\n",
            " - 0s - loss: 0.0115\n",
            "Epoch 313/500\n",
            " - 0s - loss: 0.0114\n",
            "Epoch 314/500\n",
            " - 0s - loss: 0.0115\n",
            "Epoch 315/500\n",
            " - 0s - loss: 0.0115\n",
            "Epoch 316/500\n",
            " - 0s - loss: 0.0116\n",
            "Epoch 317/500\n",
            " - 0s - loss: 0.0115\n",
            "Epoch 318/500\n",
            " - 0s - loss: 0.0114\n",
            "Epoch 319/500\n",
            " - 0s - loss: 0.0116\n",
            "Epoch 320/500\n",
            " - 0s - loss: 0.0115\n",
            "Epoch 321/500\n",
            " - 0s - loss: 0.0115\n",
            "Epoch 322/500\n",
            " - 0s - loss: 0.0115\n",
            "Epoch 323/500\n",
            " - 0s - loss: 0.0115\n",
            "Epoch 324/500\n",
            " - 0s - loss: 0.0115\n",
            "Epoch 325/500\n",
            " - 0s - loss: 0.0115\n",
            "Epoch 326/500\n",
            " - 0s - loss: 0.0115\n",
            "Epoch 327/500\n",
            " - 0s - loss: 0.0115\n",
            "Epoch 328/500\n",
            " - 0s - loss: 0.0115\n",
            "Epoch 329/500\n",
            " - 0s - loss: 0.0115\n",
            "Epoch 330/500\n",
            " - 0s - loss: 0.0115\n",
            "Epoch 331/500\n",
            " - 0s - loss: 0.0114\n",
            "Epoch 332/500\n",
            " - 0s - loss: 0.0115\n",
            "Epoch 333/500\n",
            " - 0s - loss: 0.0115\n",
            "Epoch 334/500\n",
            " - 0s - loss: 0.0114\n",
            "Epoch 335/500\n",
            " - 0s - loss: 0.0116\n",
            "Epoch 336/500\n",
            " - 0s - loss: 0.0115\n",
            "Epoch 337/500\n",
            " - 0s - loss: 0.0115\n",
            "Epoch 338/500\n",
            " - 0s - loss: 0.0115\n",
            "Epoch 339/500\n",
            " - 0s - loss: 0.0115\n",
            "Epoch 340/500\n",
            " - 0s - loss: 0.0115\n",
            "Epoch 341/500\n",
            " - 0s - loss: 0.0115\n",
            "Epoch 342/500\n",
            " - 0s - loss: 0.0115\n",
            "Epoch 343/500\n",
            " - 0s - loss: 0.0115\n",
            "Epoch 344/500\n",
            " - 0s - loss: 0.0115\n",
            "Epoch 345/500\n",
            " - 0s - loss: 0.0116\n",
            "Epoch 346/500\n",
            " - 0s - loss: 0.0115\n",
            "Epoch 347/500\n",
            " - 0s - loss: 0.0115\n",
            "Epoch 348/500\n",
            " - 0s - loss: 0.0115\n",
            "Epoch 349/500\n",
            " - 0s - loss: 0.0115\n",
            "Epoch 350/500\n",
            " - 0s - loss: 0.0114\n",
            "Epoch 351/500\n",
            " - 0s - loss: 0.0116\n",
            "Epoch 352/500\n",
            " - 0s - loss: 0.0115\n",
            "Epoch 353/500\n",
            " - 0s - loss: 0.0115\n",
            "Epoch 354/500\n",
            " - 0s - loss: 0.0115\n",
            "Epoch 355/500\n",
            " - 0s - loss: 0.0115\n",
            "Epoch 356/500\n",
            " - 0s - loss: 0.0115\n",
            "Epoch 357/500\n",
            " - 0s - loss: 0.0115\n",
            "Epoch 358/500\n",
            " - 0s - loss: 0.0115\n",
            "Epoch 359/500\n",
            " - 0s - loss: 0.0114\n",
            "Epoch 360/500\n",
            " - 0s - loss: 0.0115\n",
            "Epoch 361/500\n",
            " - 0s - loss: 0.0115\n",
            "Epoch 362/500\n",
            " - 0s - loss: 0.0115\n",
            "Epoch 363/500\n",
            " - 0s - loss: 0.0115\n",
            "Epoch 364/500\n",
            " - 0s - loss: 0.0115\n",
            "Epoch 365/500\n",
            " - 0s - loss: 0.0115\n",
            "Epoch 366/500\n",
            " - 0s - loss: 0.0115\n",
            "Epoch 367/500\n",
            " - 0s - loss: 0.0115\n",
            "Epoch 368/500\n",
            " - 0s - loss: 0.0115\n",
            "Epoch 369/500\n",
            " - 0s - loss: 0.0115\n",
            "Epoch 370/500\n",
            " - 0s - loss: 0.0115\n",
            "Epoch 371/500\n",
            " - 0s - loss: 0.0115\n",
            "Epoch 372/500\n",
            " - 0s - loss: 0.0116\n",
            "Epoch 373/500\n",
            " - 0s - loss: 0.0115\n",
            "Epoch 374/500\n",
            " - 0s - loss: 0.0115\n",
            "Epoch 375/500\n",
            " - 0s - loss: 0.0115\n",
            "Epoch 376/500\n",
            " - 0s - loss: 0.0115\n",
            "Epoch 377/500\n",
            " - 0s - loss: 0.0115\n",
            "Epoch 378/500\n",
            " - 0s - loss: 0.0116\n",
            "Epoch 379/500\n",
            " - 0s - loss: 0.0115\n",
            "Epoch 380/500\n",
            " - 0s - loss: 0.0115\n",
            "Epoch 381/500\n",
            " - 0s - loss: 0.0115\n",
            "Epoch 382/500\n",
            " - 0s - loss: 0.0113\n",
            "Epoch 383/500\n",
            " - 0s - loss: 0.0115\n",
            "Epoch 384/500\n",
            " - 0s - loss: 0.0116\n",
            "Epoch 385/500\n",
            " - 0s - loss: 0.0114\n",
            "Epoch 386/500\n",
            " - 0s - loss: 0.0115\n",
            "Epoch 387/500\n",
            " - 0s - loss: 0.0115\n",
            "Epoch 388/500\n",
            " - 0s - loss: 0.0114\n",
            "Epoch 389/500\n",
            " - 0s - loss: 0.0115\n",
            "Epoch 390/500\n",
            " - 0s - loss: 0.0115\n",
            "Epoch 391/500\n",
            " - 0s - loss: 0.0115\n",
            "Epoch 392/500\n",
            " - 0s - loss: 0.0115\n",
            "Epoch 393/500\n",
            " - 0s - loss: 0.0115\n",
            "Epoch 394/500\n",
            " - 0s - loss: 0.0115\n",
            "Epoch 395/500\n",
            " - 0s - loss: 0.0115\n",
            "Epoch 396/500\n",
            " - 0s - loss: 0.0115\n",
            "Epoch 397/500\n",
            " - 0s - loss: 0.0115\n",
            "Epoch 398/500\n",
            " - 0s - loss: 0.0115\n",
            "Epoch 399/500\n",
            " - 0s - loss: 0.0115\n",
            "Epoch 400/500\n",
            " - 0s - loss: 0.0115\n",
            "Epoch 401/500\n",
            " - 0s - loss: 0.0115\n",
            "Epoch 402/500\n",
            " - 0s - loss: 0.0115\n",
            "Epoch 403/500\n",
            " - 0s - loss: 0.0115\n",
            "Epoch 404/500\n",
            " - 0s - loss: 0.0115\n",
            "Epoch 405/500\n",
            " - 0s - loss: 0.0115\n",
            "Epoch 406/500\n",
            " - 0s - loss: 0.0115\n",
            "Epoch 407/500\n",
            " - 0s - loss: 0.0115\n",
            "Epoch 408/500\n",
            " - 0s - loss: 0.0115\n",
            "Epoch 409/500\n",
            " - 0s - loss: 0.0115\n",
            "Epoch 410/500\n",
            " - 0s - loss: 0.0115\n",
            "Epoch 411/500\n",
            " - 0s - loss: 0.0115\n",
            "Epoch 412/500\n",
            " - 0s - loss: 0.0115\n",
            "Epoch 413/500\n",
            " - 0s - loss: 0.0115\n",
            "Epoch 414/500\n",
            " - 0s - loss: 0.0115\n",
            "Epoch 415/500\n",
            " - 0s - loss: 0.0115\n",
            "Epoch 416/500\n",
            " - 0s - loss: 0.0115\n",
            "Epoch 417/500\n",
            " - 0s - loss: 0.0115\n",
            "Epoch 418/500\n",
            " - 0s - loss: 0.0114\n",
            "Epoch 419/500\n",
            " - 0s - loss: 0.0115\n",
            "Epoch 420/500\n",
            " - 0s - loss: 0.0115\n",
            "Epoch 421/500\n",
            " - 0s - loss: 0.0115\n",
            "Epoch 422/500\n",
            " - 0s - loss: 0.0114\n",
            "Epoch 423/500\n",
            " - 0s - loss: 0.0115\n",
            "Epoch 424/500\n",
            " - 0s - loss: 0.0114\n",
            "Epoch 425/500\n",
            " - 0s - loss: 0.0114\n",
            "Epoch 426/500\n",
            " - 0s - loss: 0.0116\n",
            "Epoch 427/500\n",
            " - 0s - loss: 0.0115\n",
            "Epoch 428/500\n",
            " - 0s - loss: 0.0115\n",
            "Epoch 429/500\n",
            " - 0s - loss: 0.0115\n",
            "Epoch 430/500\n",
            " - 0s - loss: 0.0115\n",
            "Epoch 431/500\n",
            " - 0s - loss: 0.0115\n",
            "Epoch 432/500\n",
            " - 0s - loss: 0.0115\n",
            "Epoch 433/500\n",
            " - 0s - loss: 0.0115\n",
            "Epoch 434/500\n",
            " - 0s - loss: 0.0115\n",
            "Epoch 435/500\n",
            " - 0s - loss: 0.0115\n",
            "Epoch 436/500\n",
            " - 0s - loss: 0.0114\n",
            "Epoch 437/500\n",
            " - 0s - loss: 0.0115\n",
            "Epoch 438/500\n",
            " - 0s - loss: 0.0115\n",
            "Epoch 439/500\n",
            " - 0s - loss: 0.0115\n",
            "Epoch 440/500\n",
            " - 0s - loss: 0.0115\n",
            "Epoch 441/500\n",
            " - 0s - loss: 0.0114\n",
            "Epoch 442/500\n",
            " - 0s - loss: 0.0115\n",
            "Epoch 443/500\n",
            " - 0s - loss: 0.0115\n",
            "Epoch 444/500\n",
            " - 0s - loss: 0.0114\n",
            "Epoch 445/500\n",
            " - 0s - loss: 0.0114\n",
            "Epoch 446/500\n",
            " - 0s - loss: 0.0115\n",
            "Epoch 447/500\n",
            " - 0s - loss: 0.0114\n",
            "Epoch 448/500\n",
            " - 0s - loss: 0.0115\n",
            "Epoch 449/500\n",
            " - 0s - loss: 0.0115\n",
            "Epoch 450/500\n",
            " - 0s - loss: 0.0115\n",
            "Epoch 451/500\n",
            " - 0s - loss: 0.0115\n",
            "Epoch 452/500\n",
            " - 0s - loss: 0.0115\n",
            "Epoch 453/500\n",
            " - 0s - loss: 0.0115\n",
            "Epoch 454/500\n",
            " - 0s - loss: 0.0115\n",
            "Epoch 455/500\n",
            " - 0s - loss: 0.0115\n",
            "Epoch 456/500\n",
            " - 0s - loss: 0.0114\n",
            "Epoch 457/500\n",
            " - 0s - loss: 0.0116\n",
            "Epoch 458/500\n",
            " - 0s - loss: 0.0115\n",
            "Epoch 459/500\n",
            " - 0s - loss: 0.0115\n",
            "Epoch 460/500\n",
            " - 0s - loss: 0.0115\n",
            "Epoch 461/500\n",
            " - 0s - loss: 0.0115\n",
            "Epoch 462/500\n",
            " - 0s - loss: 0.0115\n",
            "Epoch 463/500\n",
            " - 0s - loss: 0.0115\n",
            "Epoch 464/500\n",
            " - 0s - loss: 0.0115\n",
            "Epoch 465/500\n",
            " - 0s - loss: 0.0114\n",
            "Epoch 466/500\n",
            " - 0s - loss: 0.0115\n",
            "Epoch 467/500\n",
            " - 0s - loss: 0.0115\n",
            "Epoch 468/500\n",
            " - 0s - loss: 0.0115\n",
            "Epoch 469/500\n",
            " - 0s - loss: 0.0115\n",
            "Epoch 470/500\n",
            " - 0s - loss: 0.0115\n",
            "Epoch 471/500\n",
            " - 0s - loss: 0.0115\n",
            "Epoch 472/500\n",
            " - 0s - loss: 0.0115\n",
            "Epoch 473/500\n",
            " - 0s - loss: 0.0115\n",
            "Epoch 474/500\n",
            " - 0s - loss: 0.0114\n",
            "Epoch 475/500\n",
            " - 0s - loss: 0.0115\n",
            "Epoch 476/500\n",
            " - 0s - loss: 0.0115\n",
            "Epoch 477/500\n",
            " - 0s - loss: 0.0115\n",
            "Epoch 478/500\n",
            " - 0s - loss: 0.0115\n",
            "Epoch 479/500\n",
            " - 0s - loss: 0.0114\n",
            "Epoch 480/500\n",
            " - 0s - loss: 0.0115\n",
            "Epoch 481/500\n",
            " - 0s - loss: 0.0115\n",
            "Epoch 482/500\n",
            " - 0s - loss: 0.0115\n",
            "Epoch 483/500\n",
            " - 0s - loss: 0.0114\n",
            "Epoch 484/500\n",
            " - 0s - loss: 0.0115\n",
            "Epoch 485/500\n",
            " - 0s - loss: 0.0115\n",
            "Epoch 486/500\n",
            " - 0s - loss: 0.0115\n",
            "Epoch 487/500\n",
            " - 0s - loss: 0.0114\n",
            "Epoch 488/500\n",
            " - 0s - loss: 0.0115\n",
            "Epoch 489/500\n",
            " - 0s - loss: 0.0115\n",
            "Epoch 490/500\n",
            " - 0s - loss: 0.0115\n",
            "Epoch 491/500\n",
            " - 0s - loss: 0.0115\n",
            "Epoch 492/500\n",
            " - 0s - loss: 0.0115\n",
            "Epoch 493/500\n",
            " - 0s - loss: 0.0115\n",
            "Epoch 494/500\n",
            " - 0s - loss: 0.0115\n",
            "Epoch 495/500\n",
            " - 0s - loss: 0.0113\n",
            "Epoch 496/500\n",
            " - 0s - loss: 0.0116\n",
            "Epoch 497/500\n",
            " - 0s - loss: 0.0115\n",
            "Epoch 498/500\n",
            " - 0s - loss: 0.0114\n",
            "Epoch 499/500\n",
            " - 0s - loss: 0.0115\n",
            "Epoch 500/500\n",
            " - 0s - loss: 0.0115\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f87a3e11860>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 68
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0U34t5Rq-dFQ",
        "colab_type": "code",
        "outputId": "61d4c66d-243e-4ba3-f79d-650b1bccadde",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "# make predictions\n",
        "trainPredict = model.predict(trainX)\n",
        "testPredict = model.predict(testX)\n",
        "# invert predictions\n",
        "trainPredict = scaler.inverse_transform(trainPredict)\n",
        "trainY = scaler.inverse_transform([trainY])\n",
        "testPredict = scaler.inverse_transform(testPredict)\n",
        "testY = scaler.inverse_transform([testY])\n",
        "# calculate root mean squared error\n",
        "trainScore = math.sqrt(mean_squared_error(trainY[0], trainPredict[:,0]))\n",
        "b=50000\n",
        "print('Train Score: %.2f RMSE' % (trainScore/b))\n",
        "testScore = math.sqrt(mean_squared_error(testY[0], testPredict[:,0]))\n",
        "print('Test Score: %.2f RMSE' % (testScore/b))"
      ],
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train Score: 105.35 RMSE\n",
            "Test Score: 151.48 RMSE\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ch5Jbsnoh73m",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "3a4b44f0-6d80-4e49-9d07-1575f3839f11"
      },
      "source": [
        "print('Train Score: %.2f RMSE' % (trainScore/(b*10)))\n",
        "testScore = math.sqrt(mean_squared_error(testY[0], testPredict[:,0]))\n",
        "print('Test Score: %.2f RMSE' % (testScore/(b*10)))"
      ],
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train Score: 10.54 RMSE\n",
            "Test Score: 15.15 RMSE\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ETEOC8D2-dFT",
        "colab_type": "code",
        "outputId": "781acfe6-1510-481b-dbd5-5bab98f664b1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 276
        }
      },
      "source": [
        "# shift train predictions for plotting\n",
        "trainPredictPlot = numpy.empty_like(dataset)\n",
        "trainPredictPlot[:, :] = numpy.nan\n",
        "trainPredictPlot[look_back:len(trainPredict)+look_back, :] = trainPredict\n",
        "# shift test predictions for plotting\n",
        "testPredictPlot = numpy.empty_like(dataset)\n",
        "testPredictPlot[:, :] = numpy.nan\n",
        "testPredictPlot[len(trainPredict)+(look_back*2)+1:len(dataset)-1, :] = testPredict\n",
        "# plot baseline and predictions\n",
        "plt.plot(scaler.inverse_transform(dataset))\n",
        "plt.plot(trainPredictPlot)\n",
        "plt.plot(testPredictPlot)\n",
        "plt.show()"
      ],
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAEDCAYAAAAlRP8qAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nASgjkZX5XDIAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xGdRZ4mI-dFV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1Y1v8Lmj-dFX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}